{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d4f56e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import os\n",
    "from typing import Tuple, Dict, Any\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from causalml.inference.meta import BaseTLearner\n",
    "from causalml.metrics import plot_gain\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "18d9839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb7399a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 19:10:53,458 - INFO - Loaded dataset with shape: (2666, 20)\n",
      "2025-04-22 19:10:53,463 - INFO - Standardized column names: ['state', 'account_length', 'area_code', 'international_plan', 'voice_mail_plan', 'number_vmail_messages', 'total_day_minutes', 'total_day_calls', 'total_day_charge', 'total_eve_minutes', 'total_eve_calls', 'total_eve_charge', 'total_night_minutes', 'total_night_calls', 'total_night_charge', 'total_intl_minutes', 'total_intl_calls', 'total_intl_charge', 'customer_service_calls', 'churn']\n",
      "2025-04-22 19:10:53,525 - INFO - Preprocessing configured: 16 numeric, 3 categorical features\n",
      "2025-04-22 19:10:53,645 - INFO - Preprocessed data shape: (2666, 68)\n",
      "2025-04-22 19:10:53,662 - INFO - Train set: 1999 samples, Test set: 667 samples\n",
      "2025-04-22 19:10:56,067 - INFO - Uplift model training completed\n",
      "2025-04-22 19:10:56,630 - INFO - Saved gain plot to uplift_gain_curve.png\n",
      "2025-04-22 19:10:56,940 - INFO - Saved feature importance plot to feature_importance.png\n",
      "2025-04-22 19:10:56,941 - INFO - Evaluation results: {'model_type': 'BaseTLearner', 'test_samples': 667, 'train_samples': 1866, 'top_features': ['total_eve_minutes', 'total_intl_charge', 'total_day_minutes', 'customer_service_calls', 'total_day_charge']}\n",
      "2025-04-22 19:10:56,942 - INFO - Pipeline completed successfully: {'model_type': 'BaseTLearner', 'test_samples': 667, 'train_samples': 1866, 'top_features': ['total_eve_minutes', 'total_intl_charge', 'total_day_minutes', 'customer_service_calls', 'total_day_charge']}\n"
     ]
    }
   ],
   "source": [
    "class TelecomChurnUpliftModel:\n",
    "    def __init__(self, random_state: int = 123):\n",
    "        self.random_state = random_state\n",
    "        self.preprocessor = None\n",
    "        self.model = None\n",
    "        self.feature_names = None\n",
    "        self.target_col = 'churn'\n",
    "        self.treatment_col = 'treatment'\n",
    "        \n",
    "    def load_data(self, file_path: str) -> pd.DataFrame:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            logger.info(f\"Loaded dataset with shape: {df.shape}\")\n",
    "            df.columns = [col.lower().replace(' ', '_') for col in df.columns]\n",
    "            logger.info(f\"Standardized column names: {df.columns.tolist()}\")\n",
    "            expected_cols = [\n",
    "                'state', 'account_length', 'area_code', 'international_plan', 'voice_mail_plan',\n",
    "                'number_vmail_messages', 'total_day_minutes', 'total_day_calls', 'total_day_charge',\n",
    "                'total_eve_minutes', 'total_eve_calls', 'total_eve_charge', 'total_night_minutes',\n",
    "                'total_night_calls', 'total_night_charge', 'total_intl_minutes', 'total_intl_calls',\n",
    "                'total_intl_charge', 'customer_service_calls', 'churn'\n",
    "            ]\n",
    "            if not all(col in df.columns for col in expected_cols):\n",
    "                raise ValueError(f\"Dataset missing expected columns. Found: {df.columns.tolist()}\")\n",
    "            if df.shape[0] != 2666:\n",
    "                logger.warning(f\"Expected 2666 rows, but found {df.shape[0]} rows\")\n",
    "            df['churn'] = df['churn'].map({True: 1, False: 0, 'True': 1, 'False': 0})\n",
    "            if df['churn'].isna().any():\n",
    "                raise ValueError(\"Churn column contains missing or invalid values after mapping\")\n",
    "            np.random.seed(self.random_state)\n",
    "            df[self.treatment_col] = np.random.binomial(1, 0.5, len(df)).astype('int64')\n",
    "            binary_cols = ['international_plan', 'voice_mail_plan']\n",
    "            for col in binary_cols:\n",
    "                df[col] = df[col].str.lower().map({'yes': 1, 'no': 0, 'true': 1, 'false': 0})\n",
    "                if df[col].isna().any():\n",
    "                    raise ValueError(f\"Binary column {col} contains invalid values after mapping\")                    \n",
    "            return df\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to load data: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def setup_preprocessing(self, df: pd.DataFrame) -> None:\n",
    "        try:\n",
    "            categorical_cols = ['state', 'international_plan', 'voice_mail_plan']\n",
    "            numeric_cols = [\n",
    "                'account_length', 'area_code', 'number_vmail_messages',\n",
    "                'total_day_minutes', 'total_day_calls', 'total_day_charge',\n",
    "                'total_eve_minutes', 'total_eve_calls', 'total_eve_charge',\n",
    "                'total_night_minutes', 'total_night_calls', 'total_night_charge',\n",
    "                'total_intl_minutes', 'total_intl_calls', 'total_intl_charge',\n",
    "                'customer_service_calls'\n",
    "            ]            \n",
    "            missing_cols = [col for col in categorical_cols + numeric_cols if col not in df.columns]\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"Missing columns in dataset: {missing_cols}\")                \n",
    "            self.preprocessor = ColumnTransformer([\n",
    "                ('num', StandardScaler(), numeric_cols),\n",
    "                ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'), \n",
    "                 categorical_cols)\n",
    "            ])            \n",
    "            cat_features = []\n",
    "            for col in categorical_cols:\n",
    "                unique_vals = df[col].unique()\n",
    "                cat_features.extend([f\"{col}_{val}\" for val in unique_vals[1:] if pd.notna(val)])\n",
    "            self.feature_names = numeric_cols + cat_features            \n",
    "            logger.info(f\"Preprocessing configured: {len(numeric_cols)} numeric, \"\n",
    "                       f\"{len(categorical_cols)} categorical features\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Preprocessing setup failed: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def preprocess_data(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        try:\n",
    "            X = df.drop(columns=[self.target_col, self.treatment_col])\n",
    "            y = df[self.target_col].values\n",
    "            t = df[self.treatment_col].values            \n",
    "            if X.isna().any().any():\n",
    "                raise ValueError(\"Feature matrix contains missing values\")\n",
    "            if np.any(np.isnan(y)) or np.any(np.isnan(t)):\n",
    "                raise ValueError(\"Target or treatment arrays contain missing values\")                \n",
    "            X_processed = self.preprocessor.fit_transform(X)\n",
    "            logger.info(f\"Preprocessed data shape: {X_processed.shape}\")\n",
    "            return X_processed, y, t\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Data preprocessing failed: {str(e)}\")\n",
    "            raise            \n",
    "    def split_data(self, X: np.ndarray, y: np.ndarray, t: np.ndarray) -> Tuple:\n",
    "        try:\n",
    "            if not (X.shape[0] == y.shape[0] == t.shape[0]):\n",
    "                raise ValueError(\"Inconsistent number of samples in X, y, t\")                \n",
    "            X_train, X_test, y_train, y_test, t_train, t_test = train_test_split(\n",
    "                X, y, t,\n",
    "                test_size=0.25,\n",
    "                random_state=self.random_state,\n",
    "                stratify=y\n",
    "            )\n",
    "            logger.info(f\"Train set: {X_train.shape[0]} samples, Test set: {X_test.shape[0]} samples\")\n",
    "            return X_train, X_test, y_train, y_test, t_train, t_test\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Data splitting failed: {str(e)}\")\n",
    "            raise\n",
    "        \n",
    "    def train_uplift_model(self, X_train: np.ndarray, y_train: np.ndarray, t_train: np.ndarray) -> None:\n",
    "        try:\n",
    "            if not (X_train.shape[0] == y_train.shape[0] == t_train.shape[0]):\n",
    "                raise ValueError(\"Inconsistent number of samples in X_train, y_train, t_train\")\n",
    "            if not np.all(np.isin(t_train, [0, 1])):\n",
    "                raise ValueError(\"Treatment array must contain only 0 or 1\")\n",
    "            if not np.all(np.isin(y_train, [0, 1])):\n",
    "                raise ValueError(\"Target array must contain only 0 or 1\")                \n",
    "            self.model = BaseTLearner(\n",
    "                learner=GradientBoostingClassifier(\n",
    "                    n_estimators=100,\n",
    "                    max_depth=4,\n",
    "                    learning_rate=0.1,\n",
    "                    random_state=self.random_state\n",
    "                )\n",
    "            )\n",
    "            self.model.fit(X_train, t_train, y_train)\n",
    "            logger.info(\"Uplift model training completed\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Model training failed: {str(e)}\")\n",
    "            raise            \n",
    "    def evaluate_model(self, X_test: np.ndarray, y_test: np.ndarray, t_test: np.ndarray) -> Dict[str, Any]:\n",
    "        try:\n",
    "            if not (X_test.shape[0] == y_test.shape[0] == t_test.shape[0]):\n",
    "                raise ValueError(\"Inconsistent number of samples in X_test, y_test, t_test\")            \n",
    "            uplift_scores = self.model.predict(X_test)            \n",
    "            np.random.seed(self.random_state)\n",
    "            gain_df = pd.DataFrame({\n",
    "                'y': y_test,\n",
    "                'w': t_test,\n",
    "                'tau': uplift_scores.flatten(),\n",
    "                'random': np.random.uniform(-1, 1, size=len(y_test))\n",
    "            })\n",
    "            if gain_df.isna().any().any():\n",
    "                raise ValueError(\"Gain DataFrame contains missing values\")            \n",
    "            fig1 = plt.figure(figsize=(10, 6))\n",
    "            plot_gain(\n",
    "                gain_df,\n",
    "                outcome_col='y',\n",
    "                treatment_col='w',\n",
    "                treatment_effect_col='tau'\n",
    "            )\n",
    "            plt.title('Cumulative Gain Curve - T-Learner Uplift Model')\n",
    "            plt.grid(True)\n",
    "            gain_plot_path = 'uplift_gain_curve.png'\n",
    "            plt.savefig(gain_plot_path, bbox_inches='tight')\n",
    "            logger.info(f\"Saved gain plot to {gain_plot_path}\")\n",
    "            plt.close(fig1)            \n",
    "            importance = self.model.models_t[1].feature_importances_\n",
    "            top_features = [\n",
    "                self.feature_names[i] for i in np.argsort(importance)[-5:]\n",
    "            ]            \n",
    "            fig2 = plt.figure(figsize=(10, 8))\n",
    "            sns.barplot(x=importance[np.argsort(importance)[-5:]], y=top_features)\n",
    "            plt.title('Top 5 Feature Importances - T-Learner')\n",
    "            feature_plot_path = 'feature_importance.png'\n",
    "            plt.savefig(feature_plot_path, bbox_inches='tight')\n",
    "            logger.info(f\"Saved feature importance plot to {feature_plot_path}\")\n",
    "            plt.close(fig2)            \n",
    "            results = {\n",
    "                'model_type': 'BaseTLearner',\n",
    "                'test_samples': len(X_test),\n",
    "                'train_samples': X_train.shape[0],\n",
    "                'top_features': top_features\n",
    "            }\n",
    "            logger.info(f\"Evaluation results: {results}\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Model evaluation failed: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "def execute_uplift_pipeline(file_path: str) -> Dict[str, Any]:\n",
    "    try:\n",
    "        model = TelecomChurnUpliftModel(random_state=123)        \n",
    "        df = model.load_data(file_path)        \n",
    "        model.setup_preprocessing(df)        \n",
    "        X, y, t = model.preprocess_data(df)        \n",
    "        X_train, X_test, y_train, y_test, t_train, t_test = model.split_data(X, y, t)        \n",
    "        model.train_uplift_model(X_train, y_train, t_train)        \n",
    "        results = model.evaluate_model(X_test, y_test, t_test)        \n",
    "        logger.info(f\"Pipeline completed successfully: {results}\")\n",
    "        return results        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Pipeline execution failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    file_path = './churn-bigml-80.csv'\n",
    "    execute_uplift_pipeline(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
